# TIL
## 24.02.27
### 한 일
- 주제 선정 회의
- 주제 구체화
- 컨설턴트님과 코치님과의 컨설팅

### 배운 것
- 아이디어에는 핵심이 되는 메인 기능이 있어야 한다.
- 하둡 및 스파크의 공통점과 차이점
    - 공통점
        - 빅데이터 처리
        - 오픈소스
        - 분산처리
    - 차이점
        - 처리방식 : 하둡은 디스크기반 처리 방식, 스파크는 메모리기반 처리 방식
        - 속도 : 스파크는 메모리에서 처리하기 때문에 더 빠름
        - 용도 : 하둡은 대용량 처리, 스파크는 실시간 처리, 반복적인 작업, 머신러닝, 그래프 처리에 적합
        - API 지원 : 하둡은 Java 기반 지원, 스파크는 Java, Scala, Python, R 등 지원

### 아직 잘 모르는 것
- [X] 하둡과 스파크 사용 방법
- [] 뉴스 데이터 크롤링 및 분산 처리 방법

## 24.02.28
### 한 일
- 아이디어 회의
- 아이디어 확정
- 기획서 작성
- [공통 프로젝트 백엔드 개발 리뷰 작성 완료](https://ksb-dev.tistory.com/348)

### 배운 것
- HDFS(Hadoop Distributed File System)
    - 장애 복구성을 가지는 분산 파일 시스템
- 블록 단위 저장
    - 일정 블록 크기를 저장
    - 블록사이즈보다 작은 파일은 기존 파일 사이즈로 저장, 큰 파일은 블록 단위로 나누어 저장
- 데이터 지역성
    - 처리 속도 증가를 위해 사용
- HDFS Federation
    - 하둡 v2부터 적용
    - 디렉토리(네임스페이스) 단위로 네임로드 등록해서 사용
    - 하둡 v1에서는 단일 네임노드만 사용해서 병목 현상으로 성능 이슈가 있었는데, 이 기술로 해결함
- Spring은 ObjectMapper로 Controller 파라미터에 Dto를 넣어준다. 지금까지 Dto는 setter가 필요한 줄 알아서 @Data를 썼는데, getter만 있어도 된다는 것을 알게 되었다.

### 아직 모르는 것
- 오늘은 모르는 것이 없다.

## 24.03.04
### 한 일
- 전문가 리뷰 자료 수정
- 뉴스 크롤링
- 스파크 학습

### 배운 것
- 크롤링 ip 차단
    - 많은 뉴스 사이트가 사람이 할 수 없는 요청에 대해 ip를 차단시킨다.
        - 서울 뉴스의 경우 일반적으로 사람이 할 수 없는 요청이 20개가 넘어가면 ip 차단을 당하는거 같다.
    - 스파크 DF 조인 방법
        - SQL 방법과 다르지 않다.
        - QueryDSL처럼 사용 가능
            ```
            df_user.join(df_salary,
                df_user.id == df_salary.id,
                "inner").show()
            ```
    - PySpark의 collect()가 결과를 로컬에 수집할 때, 데이터를 리스트의 리스트로 반환하기 때문에, 이차원에서 데이터 접근 가능
        ```
        mean_value[0][0]
        ```


### 아직 잘 모르는 것
- [] 한겨레에서 ip 차단을 하는 검증 방법
- [] 스파크 데이터 전처리