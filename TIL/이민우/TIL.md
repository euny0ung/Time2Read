# 2024-02-27

## 한 일
- 특화 프로젝트 아이디어 회의
- 기업 관련 데이터 조사
- TDD 관련 학습


## 배운 것
- 통합테스트를 실행하려면 DB나 캐시 서버와 같은 연동 대상을 구성해야 한다. 기능 테스트를 실행하려면 웹 서버를 구동하거나 모바일 앱을 폰에 설치해야 할 수도 있다. 또한 통합 테스트나 기능 테스트는 테스트 상황을 만들어내기 위해 많은 노력이 필요하다. 반면에 단위 테스트는 테스트 코드를 빼면 따로 준비할 것이 없다.
- 통합테스트는 DB 연결, 소켓통신, 스프링 컨테이너 초기화와 같이 테스트 실행 속도를 느리게 만드는 요인이 많다. 기능 테스트는 추가로 브라우저나 앱을 구동하고 화면의 흐름에 따라 알맞은 상호작용을 해야한다. 반면에 단위 테스트는 서버를 구동하거나 DB를 준비할 필요가 없다. 테스트 대상이 의존하는 기능을 대역으로 처리하면 되므로 테스트 실행속도가 빠르다.
- 통합 테스트나 기능테스트로는 상황을 준비하거나 결과확인이 어렵거나 불가능할 때가 있다. 외부 시스템과 연동해야 하는 기능이 특히 그렇다. 이런 경우에는 단위 테스트와 대역을 조합해서 상황을 만들고 결과를 확인해야 한다.

- TDD를 하는지 여부에 상관없이 테스트 코드를 작성하는 개발자는 단위 테스트와 통합테스트를 섞어서 작성한다.
- 통합테스트는 필요하다. 단위 테스트를 많이 만든다고 해도 결국은 각 구성요소가 올바르게 연동되는 것을 확인해야 하는데 이를 자동화하기 좋은 수단이 통합테스트 코드이기 때문이다.
- 통합 테스트보다 단위 테스트가 빠르기 때문에 가능하면 단위 테스트에서 다양한 상황을 다루고, 통합 테스트나 기능테스트는 주요 상황에 초점을 맞춰야한다. 그래야 테스트 실행시간이 증가해 피드백이 느려지는 것을 방지 할 수 있다. 테스트 실행 속도가 느려지면 테스트를 작성하지 않거나 테스트 실행을 생략하는 상황이 벌어진다.

## 하루 회고
- 프로젝트 일정 중에서 기획 단계가 제일 힘들다. 에너지만 들어가고 결과는 뜻대로 나오지 않는다. 하지만 절대 무의미하다고 생각하지 않는다. 팀원들과 이런 저런 이야기를 나누며 오히려 팀원들에 대해 깊게 파악할 수 있는 시간이었고, 무지성 아이디어를 내놓으며 즐겁기도 한 순간도 있었다. 물론 지금 이 순간은 괴롭지만 먼 미래에서 바라봤을 때 행복했던 추억이 되겠지..
- 집에 오면 너무 피곤한데 어쩌지.. 체력을 어떻게든 늘려봐야 하는데.. 
---
# 2024-02-28

## 한 일
- 특화 프로젝트 아이디어 회의
- TDD 스터디

## 배운 것
### Airflow[[참고](https://www.bucketplace.com/post/2021-04-13-%EB%B2%84%ED%82%B7%ED%94%8C%EB%A0%88%EC%9D%B4%EC%8A%A4-airflow-%EB%8F%84%EC%9E%85%EA%B8%B0/)]
- Airflow란
    - Airflow는 Python 코드로 워크플로우를 작성하고, 스케줄링, 모니터링 하는 플랫폼이다. Airflow를 통해서 데이터 엔지니어링의 ETL(Extract, Transform, Load) 작업을 자동화 하고, DAG(Directed Acyclic Graph) 형태의 워크 플로우 작성이 가능하다. 이를 통해 더 정교한 Dependency를 가진 파이프라인을 설정할 수 있다.
- Airflow 동작원리
![Airflow 동작원리](https://res.cloudinary.com/bucketplace-co-kr/image/upload/w_1000/airflow_4.png)
    - Scheduler : 모든 DAG와 Task에 대하여 모니터링 및 관리하고, 실행해야할 Task를 스케줄링 해줍니다.
    - Web server : Airflow의 웹 UI 서버
    - DAG : Directed Acyclic Graph로 개발자가 Python으로 작성한 워크플로우. Task들의 dependency를 정의
    - Database : Airflow에 존재하는 DAG와 Task들의 메타데이터를 저장하는 데이터베이스
    - Worker : 실제 Task를 실행하는 주체. Executor 종류에 따라 동작 방식이 다양
    - Airflow는 개발자가 작성한 Python DAG를 읽고, 거기에 맞춰 Scheduler가 Task를 스케줄링하면, Worker가 Task를 가져가 실행한다. Task의 실행상태는 Database에 저장되고, 사용자는 UI를 통해서 각 Task의 실행상태, 성공 여부 등을 확인할 수 있다.
- 장점[[참고](https://velog.io/@sophi_e/Airflow-%EA%B8%B0%EC%B4%88-%EA%B0%9C%EB%85%90-%EB%B0%8F-%EC%9E%A5%EB%8B%A8%EC%A0%90)]
    - 파이썬 코드를 이용하여 파이프라인을 구현하므로 파이썬 언어에서 구현할 수 있는 대부분의 방법을 사용하여 복잡한 커스텀 파이프라인을 만들 수 있음
    - 데이터 인프라 관리, 데이터 웨어하우스 구축, 머신러닝/분석/실험에 데이터 환경 구성에 유용
    - 에어플로우의 스케줄링 기능으로 DAG에 정의된 특정 시점에 트리거할 수 있을 뿐만 아니라 최종 시점과 예상되는 다음 스케줄 주기를 상세하게 알려줌
- 단점
    - 작은 환경 변화에도 오류가 쉽게 날 수 있음
    - Data Streaming Solution 적용에는 적합하지 않다.
        - 초 단위의 데이터 처리가 필요한 경우에 사용하기에는 부적절함
        - 에어플로우는 반복적이거나 배치태스크를 실행하는 기능에 초점이 맞춰져있다.
    - Data Processing Framework(Flink, Spark, Hadoop 등)로 사용하는 것은 부적절
        - 데이터 프로세싱 작업에 최적화되어있지 않아 매우 느림
        - 경우에 따라 메모리 부족으로 작업이 진행되지 않을 수 있음
            -> `SparkSubmitOperator`와 같은 Operator를 이용하여, 데이터 프로세싱은 Spark와 같은 외부 Framework로 처리

## 아직 잘 모르는 것
- Airflow에 대한 이론만 간단히 살펴보았다. 스프링 배치와 비슷한 느낌이 드는 것 같다. 앞으로 파이썬을 통해 크롤링하고 데이터 전처리 작업을 거칠 것 같은데 Airflow를 사용하는 방법을 좀 더 알아봐야 할 것 같다.

## 하루 회고
- 시간이 부족한 탓에 아이디어 기획을 기존의 아이디어로 강제 fix하게 되었다. 뉴스라는 데이터를 활용하여 무언가를 보여줄 것인데, 서비스를 사용할 사용자들에게 어떤 유의미한 정보를 보여줄 수 있을지 많은 고민을 해봐야한다. 데이터 라벨링을 어떻게, 어디까지 가져가야할까가 나의 고민이다. 암튼 현재 기획한 내용에서 빅데이터 활용 측면이 약해보이니 조금 더 고민해보자.
- TDD 스터디가 끝나고 스터디원들과 이야기를 나누는 도중 기록의 중요성을 알게 되었다. 학습 내용 공유라던가, 트러블 슈팅한 경험을 모두 기록하는 것이 나뿐만 아니라 팀원 모두에게 도움이 될 듯하다. 전 공통 프로젝트에서는 원활한 문서 작업이 이뤄지지 않았지만 이번에는 제대로 해볼 계획이다.   
---
# 2024-03-04

## 한 일
- 한겨레 기사 분석
- 한겨레 기사 크롤링
- 데이터 분산 처리 학습
- TDD 스터디 준비

## 배운 것
### 데이터 엔지니어링
수집
- 다양한 서비스에서 생성된 데이터들을 모으는 일
- 데이터 파이프라인
- 배치 또는 스트리밍

시스템 구축
- 파이프라인을 어떻게 구축할 것인가?
- 적절한 기술의 선택, 의사 결정
- 배치 처리, 스트리밍 처리

분석과 데이터 사이언스
- 쿼리를 통한 분석, 분석 시스템
- 어떻게 전달할 것인가 → Visualization, Dashboard
- Feautre Engineering

데이터 처리
- 모델을 위한 데이터 전처리
- 생성일자, 업데이트 일자 등등의 Timestamp 처리

### 분산시스템이란?
- 분산되어 있는 여러 서버를 하나의 서버처럼 다루는 시스템
- 왜 분산 시스템이 필요할까?
    - 고가용성 : 서버와 네트워크, 프로그램 등의 정보 시스템이 상당히 오랜 기간 지속적으로 정상 운영이 가능한 성질
    - 한 서버는 장애가 날 것이라고 가정. 장애가 없는 서버는 없다.
    - 장애에 대한 대응 시스템 - 장애를 방어할 수 있는 시스템이 바로 분산 시스템
    - 한 서버가 고장이 나면 다른 서버에서 처리할 수 있도록
    - 대표적인 방식이 복제
- 고가용성 : 한 서버 또는 여러 장비나 전체 데이터센터가 다운될 때도 시스템이 계속 동작하게 한다.
- 지연 시간 : 지리적으로 사용자에게 가까이 데이터를 배치해 사용자가 더 빠르게 작업할 수 있게한다.
- 확장성 : 복제본에서 읽기를 수행해 단일 장비에서 다룰 수 있는 양보다 많은 양의 읽기 작업을 처리할 수 있다.

### 분산 시스템의 문제점
- 분산 시스템은 완전하지 않다.
- 결함이 발견되었을 때 시스템이 이를 견딜 수 있게 만들기도 쉽지 않다.
- 한 노드에서 다른 노드로 정보가 흐를 수 있는 유일한 방법은 신뢰성이 없는 네트워크로 보내는 것
- 시스템이 커질수록 구성요소 하나가 고장 날 가능성이 높아짐
- 결함이 생겼다면, 잘못된 결과를 내는것이?? → 아니 차라리 동작 안하는 것이 좋다.
- 예측할 수 없는 방식으로 고장나는 것 → 부분장애
- 어떨 때는 동작하지만 어떨 때는 예측되지 않는 방식으로 실패 → 비결정성

## 아직 잘 모르는 것
- 크롤링한 뉴스 데이터들을 어떤식으로 분산 처리해야 효율적일까?
- 대용량의 데이터라면 분명 처리할 때 에러가 발생할텐데 어떻게 처리? 파티셔닝?

## 하루 회고
- 크롤링을 하며 IP도 차단당하고, 생각보다 수집해야하는 데이터들이 너무 많아 걱정이 많았지만!? 방법은 어떻게든 있으니 할 수 있으리라 믿는다. 우리팀 조금 더 힘내자!!
- 분산처리 공부 빨리빨리! 갈 길이 멀다.
